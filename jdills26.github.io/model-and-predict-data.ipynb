{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import standard packages\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mport the random forest package # it's the best model used so far but i want to prove that\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import logistic reg as well\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "#importing these but may not use all of them\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load the cleaned training values\n",
    "train = pd.read_csv('cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load the cleaned test set\n",
    "test = pd.read_csv('cleaned_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#drop this unnamed column \n",
    "train.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "test.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fill NaN values with the mean\n",
    "train[\"construction_year\"].fillna(train[\"construction_year\"].mean(), inplace=True)\n",
    "train[\"operation_year\"].fillna(train[\"operation_year\"].mean(), inplace=True)\n",
    "test[\"construction_year\"].fillna(test[\"construction_year\"].mean(), inplace=True)\n",
    "test[\"operation_year\"].fillna(test[\"construction_year\"].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'amount_tsh',\n",
       " 'gps_height',\n",
       " 'longitude',\n",
       " 'latitude',\n",
       " 'num_private',\n",
       " 'region_code',\n",
       " 'district_code',\n",
       " 'population',\n",
       " 'construction_year',\n",
       " 'operation_year',\n",
       " 'month_recorded',\n",
       " 'season']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get numeric columns for model from train df\n",
    "[(col, dtype) for col, dtype in zip(train.columns, train.dtypes) if dtype != 'object']\n",
    "num_columns = [col for col, dtype in zip(train.columns, train.dtypes) if dtype != 'object']\n",
    "num_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'amount_tsh',\n",
       " 'gps_height',\n",
       " 'longitude',\n",
       " 'latitude',\n",
       " 'num_private',\n",
       " 'region_code',\n",
       " 'district_code',\n",
       " 'population',\n",
       " 'construction_year',\n",
       " 'operation_year',\n",
       " 'month_recorded',\n",
       " 'season']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get numeric columns for model from test df\n",
    "[(col, dtype) for col, dtype in zip(test.columns, test.dtypes) if dtype != 'object']\n",
    "num_columns_test = [col for col, dtype in zip(test.columns, test.dtypes) if dtype != 'object']\n",
    "num_columns_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#going to define feature columns for model because I don't want all of these num_columns \n",
    "#these features are a work in progress - want to factorize water type/quality and maintenance system\n",
    "feature_columns = [\n",
    " 'amount_tsh',\n",
    " 'gps_height',\n",
    " 'longitude',\n",
    " 'latitude',\n",
    " 'region_code',\n",
    " 'district_code',\n",
    " 'population',\n",
    " 'construction_year',\n",
    " 'operation_year', \n",
    " 'season']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = train[feature_columns]\n",
    "y = train.status_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = test[feature_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try with logistic regression to establish a baseline\n",
    "model = LogisticRegression()\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.59771082,  0.60242383,  0.58761151,  0.58777984,  0.58417508,\n",
       "        0.58552189,  0.59393939,  0.59622832,  0.59252399,  0.59279219])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(model, X, y, 'accuracy', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try with rfc and see if cross_val_score improves\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.71149638,  0.71907086,  0.71065477,  0.70846659,  0.72020202,\n",
       "        0.70858586,  0.71734007,  0.69944435,  0.70213841,  0.70882452])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(model, X, y, 'accuracy', cv=10)\n",
    "#these scores are improved "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try again and specify n_estimators 100\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.7185659 ,  0.73051675,  0.71620939,  0.72226898,  0.73198653,\n",
       "        0.71919192,  0.73114478,  0.70786328,  0.71712409,  0.72364432])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(model, X, y, 'accuracy', cv=10)\n",
    "#these scores are improved but not that much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try again and specify n_estimators 100\n",
    "model = RandomForestClassifier(n_estimators=1000)\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#am not going to run the cross_val_score because it is taking too long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05445317,  0.11481486,  0.28526193,  0.28087867,  0.02705655,\n",
       "        0.03252202,  0.07535033,  0.05932817,  0.05532201,  0.0150123 ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at feature importance\n",
    "importances = model.feature_importances_\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 2 (0.285262)\n",
      "2. feature 3 (0.280879)\n",
      "3. feature 1 (0.114815)\n",
      "4. feature 6 (0.075350)\n",
      "5. feature 7 (0.059328)\n",
      "6. feature 8 (0.055322)\n",
      "7. feature 0 (0.054453)\n",
      "8. feature 5 (0.032522)\n",
      "9. feature 4 (0.027057)\n",
      "10. feature 9 (0.015012)\n"
     ]
    }
   ],
   "source": [
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#in order: \n",
    "#2-longitude, 3-latitude, 1-elevation, 6-population\n",
    "#7-construction year, 8-operation year, 0-free/not free (amt tsh)\n",
    "#5-district, 6-region, 9-season\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create status_group column on test df\n",
    "test['status_group'] = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#export it to csv\n",
    "pd.DataFrame(test['status_group']).to_csv(\"submission11.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#looking forward to factorizing additional categorical variables\n",
    "#want to calculate ROC and F1 score by doing train-test split on training df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
